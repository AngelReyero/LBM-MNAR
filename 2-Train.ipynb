{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the model for parliament dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0- Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from fcts.train_procedure import train_with_LBFGS\n",
    "from fcts.lbm_nmar import LBM_NMAR\n",
    "from fcts.utils import reparametrized_expanded_params, init_random_params, save_objects_to_yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Load torch parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (for Mac) %env PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0\n",
    "device = 'mps' #put 'cuda', 'cpu' or 'mps' (for Mac)\n",
    "device2 = 'mps' #put None, 'cuda' or 'mps' (for Mac)\n",
    "\n",
    "if not torch.backends.mps.is_available() and device != 'cpu':\n",
    "    print('Cuda is not available. Algorithm will use cpu')\n",
    "    device, device2 = torch.device('cpu'), None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Load parliament datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#votes: matrix gathering votes for several laws and politicians (1: positive, 0: missing/abstention, -1: negative)\n",
    "votes = np.loadtxt(\"data_parliament/votes.txt\",delimiter=\";\").astype(int)\n",
    "\n",
    "#deputes: Family name, Name, Political group \n",
    "deputes = json.load(open('data_parliament/deputes.json', 'r')) \n",
    "\n",
    "#texts:  political group demanding the law, title of demand, date, type (type of vote, type of majority, name of type of vote), \n",
    "texts = json.load(open('data_parliament/texts.json', 'r')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices\n",
    "indices_p = np.argwhere(votes == 1) #argwhere: matrix with couples (row,column) with 1 values \n",
    "indices_n = np.argwhere(votes == -1) #idem with -1\n",
    "indices_zeros = np.argwhere(votes == 0) #idem with 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a - Parameter initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of votes dataset: number of rows and columns\n",
    "n1, n2 = votes.shape\n",
    "\n",
    "# Select number of row clusters\n",
    "nq = 3# COMPLETE\n",
    "\n",
    "# Select number of column clusters\n",
    "nl = 5 # COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization of ($\\gamma, \\theta$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_of_parameters = torch.tensor(init_random_params(n1, n2, nq, nl), requires_grad=True, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b- Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LBM_NMAR(\n",
    "    vector_of_parameters,\n",
    "    votes,\n",
    "    (n1, n2, nq, nl),\n",
    "    device=device,\n",
    "    device2=device2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c- Train model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform variational EM: \n",
    "\n",
    "VEM step % 2 = 0: VE step, where we maximize the variational parameters $\\gamma$\n",
    "\n",
    "\n",
    "VEM step % 2 = 1: M step, where we maximize the model parameters $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "Start training LBM MNAR \n",
      " --------------------------------------------------------------------------------\n",
      "Number of row classes :  3\n",
      "Number of col classes :  5\n",
      " VEM step  |   LBFGS iter  | criteria |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurafuentesvicente/M2 Maths&IA/Methodes Non Supervises avancees/Projet/LBM-MNAR/fcts/lbfgs.py:339: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
      "  p.data.add_(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0  |   1  | 344662.09375 |\n",
      " 0  |   2  | 325378.46875 |\n",
      " 0  |   3  | 319908.37500 |\n",
      " 0  |   4  | 316734.12500 |\n",
      " 0  |   5  | 315405.62500 |\n",
      " 0  |   6  | 314782.00000 |\n",
      " 0  |   7  | 314366.06250 |\n",
      " 0  |   8  | 314101.15625 |\n",
      " 0  |   9  | 313902.37500 |\n",
      " 0  |   10  | 313667.00000 |\n",
      " 0  |   11  | 313402.00000 |\n",
      " 0  |   12  | 313043.31250 |\n",
      " 0  |   13  | 312651.81250 |\n",
      " 0  |   14  | 312207.00000 |\n",
      " 0  |   15  | 311776.03125 |\n",
      " 0  |   16  | 311250.28125 |\n",
      " 0  |   17  | 310724.81250 |\n",
      " 0  |   18  | 310171.21875 |\n",
      " 0  |   19  | 310031.15625 |\n",
      " 0  |   20  | 309954.31250 |\n",
      " 0  |   21  | 309918.50000 |\n",
      " 0  |   22  | 309913.56250 |\n",
      " 0  |   23  | 309912.68750 |\n",
      " 0  |   24  | 309912.68750 |\n",
      "------------------------------  Optimizing next EM step  ------------------------------\n",
      " EM step  |   LBFGS iter  | criteria |\n",
      " 1  |   1  | 309146.65625 |\n",
      " 1  |   2  | 308091.28125 |\n",
      " 1  |   3  | 307221.03125 |\n",
      " 1  |   4  | 307128.18750 |\n",
      " 1  |   5  | 306881.78125 |\n",
      " 1  |   6  | 306689.62500 |\n",
      " 1  |   7  | 306555.90625 |\n",
      " 1  |   8  | 306506.84375 |\n",
      " 1  |   9  | 306487.43750 |\n",
      " 1  |   10  | 306469.75000 |\n",
      " 1  |   11  | 306462.50000 |\n",
      " 1  |   12  | 306459.93750 |\n",
      " 1  |   13  | 306452.75000 |\n",
      " 1  |   14  | 306450.06250 |\n",
      " 1  |   15  | 306448.56250 |\n",
      " 1  |   16  | 306448.50000 |\n",
      " 1  |   17  | 306448.46875 |\n",
      " 1  |   18  | 306448.37500 |\n",
      " 1  |   19  | 306448.31250 |\n",
      " 1  |   20  | 306448.25000 |\n",
      " 1  |   21  | 306448.25000 |\n",
      "------------------------------  Optimizing next EM step  ------------------------------\n",
      " EM step  |   LBFGS iter  | criteria |\n",
      " 2  |   1  | 306134.00000 |\n",
      " 2  |   2  | 305939.78125 |\n",
      " 2  |   3  | 305742.31250 |\n",
      " 2  |   4  | 305653.25000 |\n",
      " 2  |   5  | 305556.37500 |\n",
      " 2  |   6  | 305505.53125 |\n",
      " 2  |   7  | 305424.50000 |\n",
      " 2  |   8  | 305371.84375 |\n",
      " 2  |   9  | 305264.75000 |\n",
      " 2  |   10  | 305156.18750 |\n",
      " 2  |   11  | 304918.00000 |\n",
      " 2  |   12  | 304775.68750 |\n",
      " 2  |   13  | 304490.12500 |\n",
      " 2  |   14  | 304201.90625 |\n",
      " 2  |   15  | 303723.65625 |\n",
      " 2  |   16  | 303329.09375 |\n",
      " 2  |   17  | 302735.96875 |\n",
      " 2  |   18  | 302114.81250 |\n",
      " 2  |   19  | 302032.18750 |\n",
      " 2  |   20  | 301990.21875 |\n",
      " 2  |   21  | 301988.93750 |\n",
      " 2  |   22  | 301988.68750 |\n",
      " 2  |   23  | 301988.65625 |\n",
      " 2  |   24  | 301988.65625 |\n",
      "------------------------------  Optimizing next EM step  ------------------------------\n",
      " EM step  |   LBFGS iter  | criteria |\n",
      " 3  |   1  | 301975.12500 |\n",
      " 3  |   2  | 301962.65625 |\n",
      " 3  |   3  | 301929.34375 |\n",
      " 3  |   4  | 301881.18750 |\n",
      " 3  |   5  | 301835.65625 |\n",
      " 3  |   6  | 301828.81250 |\n",
      " 3  |   7  | 301827.68750 |\n",
      " 3  |   8  | 301826.28125 |\n",
      " 3  |   9  | 301823.78125 |\n",
      " 3  |   10  | 301819.75000 |\n",
      " 3  |   11  | 301815.09375 |\n",
      " 3  |   12  | 301811.87500 |\n",
      " 3  |   13  | 301809.37500 |\n",
      " 3  |   14  | 301806.40625 |\n",
      " 3  |   15  | 301802.93750 |\n",
      " 3  |   16  | 301801.50000 |\n",
      " 3  |   17  | 301801.25000 |\n",
      " 3  |   18  | 301801.00000 |\n",
      " 3  |   19  | 301800.75000 |\n",
      " 3  |   20  | 301800.62500 |\n",
      " 3  |   21  | 301800.40625 |\n",
      " 3  |   22  | 301799.81250 |\n",
      " 3  |   23  | 301799.31250 |\n",
      " 3  |   24  | 301799.21875 |\n",
      " 3  |   25  | 301799.15625 |\n",
      " 3  |   26  | 301799.15625 |\n",
      "------------------------------  Optimizing next EM step  ------------------------------\n",
      " EM step  |   LBFGS iter  | criteria |\n",
      " 4  |   1  | 301505.34375 |\n",
      " 4  |   2  | 301203.71875 |\n",
      " 4  |   3  | 300918.59375 |\n",
      " 4  |   4  | 300708.12500 |\n",
      " 4  |   5  | 300589.40625 |\n",
      " 4  |   6  | 300492.87500 |\n",
      " 4  |   7  | 300365.25000 |\n",
      " 4  |   8  | 300252.93750 |\n",
      " 4  |   9  | 300172.31250 |\n",
      " 4  |   10  | 300113.75000 |\n",
      " 4  |   11  | 300027.06250 |\n",
      " 4  |   12  | 299918.34375 |\n",
      " 4  |   13  | 299753.96875 |\n",
      " 4  |   14  | 299563.75000 |\n",
      " 4  |   15  | 299261.56250 |\n",
      " 4  |   16  | 298960.15625 |\n",
      " 4  |   17  | 298546.90625 |\n",
      " 4  |   18  | 297892.46875 |\n",
      " 4  |   19  | 297848.34375 |\n",
      " 4  |   20  | 297811.62500 |\n",
      " 4  |   21  | 297807.78125 |\n",
      " 4  |   22  | 297805.84375 |\n",
      " 4  |   23  | 297805.18750 |\n",
      " 4  |   24  | 297804.59375 |\n",
      " 4  |   25  | 297804.59375 |\n",
      "------------------------------  Optimizing next EM step  ------------------------------\n",
      " EM step  |   LBFGS iter  | criteria |\n",
      " 5  |   1  | 297597.28125 |\n",
      " 5  |   2  | 297306.03125 |\n",
      " 5  |   3  | 297202.46875 |\n",
      " 5  |   4  | 297185.84375 |\n",
      " 5  |   5  | 297144.50000 |\n",
      " 5  |   6  | 297116.12500 |\n",
      " 5  |   7  | 297096.56250 |\n",
      " 5  |   8  | 297087.31250 |\n",
      " 5  |   9  | 297081.03125 |\n",
      " 5  |   10  | 297076.84375 |\n",
      " 5  |   11  | 297076.28125 |\n",
      " 5  |   12  | 297076.18750 |\n",
      " 5  |   13  | 297075.96875 |\n",
      " 5  |   14  | 297074.90625 |\n",
      " 5  |   15  | 297073.37500 |\n",
      " 5  |   16  | 297072.93750 |\n",
      " 5  |   17  | 297072.56250 |\n",
      " 5  |   18  | 297072.50000 |\n",
      " 5  |   19  | 297072.46875 |\n",
      " 5  |   20  | 297072.37500 |\n",
      " 5  |   21  | 297072.18750 |\n",
      " 5  |   22  | 297072.03125 |\n",
      " 5  |   23  | 297071.93750 |\n",
      " 5  |   24  | 297071.93750 |\n",
      "------------------------------  Optimizing next EM step  ------------------------------\n",
      " EM step  |   LBFGS iter  | criteria |\n",
      " 6  |   1  | 296820.28125 |\n",
      " 6  |   2  | 296603.50000 |\n",
      " 6  |   3  | 296317.56250 |\n",
      " 6  |   4  | 296187.59375 |\n",
      " 6  |   5  | 296094.37500 |\n",
      " 6  |   6  | 295864.03125 |\n",
      " 6  |   7  | 295747.18750 |\n",
      " 6  |   8  | 295614.90625 |\n",
      " 6  |   9  | 295405.18750 |\n",
      " 6  |   10  | 295150.71875 |\n",
      " 6  |   11  | 294928.50000 |\n",
      " 6  |   12  | 294795.59375 |\n",
      "Objective function is NAN. Probably due to empty class\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    success, loglike = train_with_LBFGS(model)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt detected, stopping training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reparametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(   nu_a,\n",
    "    rho_a,\n",
    "    nu_b,\n",
    "    rho_b,\n",
    "    nu_p,\n",
    "    rho_p,\n",
    "    nu_q,\n",
    "    rho_q,\n",
    "    tau_1,\n",
    "    tau_2,\n",
    "    mu_un,\n",
    "    sigma_sq_a,\n",
    "    sigma_sq_b,\n",
    "    sigma_sq_p,\n",
    "    sigma_sq_q,\n",
    "    alpha_1,\n",
    "    alpha_2,\n",
    "    pi,\n",
    ") = reparametrized_expanded_params(torch.cat((model.variationnal_params, model.model_params)), n1, n2, nq, nl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save parameters in YAML file (trained_parameters.yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict = {\n",
    "    'n1': n1, \n",
    "    'n2': n2,\n",
    "    'nq': nq, \n",
    "    'nl': nl,\n",
    "    'nu_a':nu_a,\n",
    "    'rho_a':rho_a,\n",
    "    'nu_b':nu_b,\n",
    "    'rho_b':rho_b,\n",
    "    'nu_p': nu_p,\n",
    "    'rho_p':rho_p,\n",
    "    'nu_q':nu_q,\n",
    "    'rho_q':rho_q,\n",
    "    'tau_1':tau_1,\n",
    "    'tau_2':tau_2,\n",
    "    'mu_un':mu_un,\n",
    "    'sigma_sq_a': sigma_sq_a,\n",
    "    'sigma_sq_b':sigma_sq_b,\n",
    "    'sigma_sq_p':sigma_sq_p,\n",
    "    'sigma_sq_q':sigma_sq_q,\n",
    "    'alpha_1':alpha_1,\n",
    "    'alpha_2':alpha_2,\n",
    "    'pi':pi,\n",
    "    'indices_p': indices_p,\n",
    "    'indices_n':indices_n,\n",
    "    'indices_zeros': indices_zeros,\n",
    "    'device': device, \n",
    "    'device2': device2,\n",
    "}\n",
    "\n",
    "save_objects_to_yaml(parameters_dict, 'trained_parameters.yaml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
