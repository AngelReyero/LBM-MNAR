{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the model for parliament dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0- Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from fcts.train_procedure import train_with_LBFGS\n",
    "from fcts.lbm_nmar import LBM_NMAR\n",
    "from fcts.lbfgs import FullBatchLBFGS\n",
    "from fcts.figures import groupes_politiques, pi_df, text_legend_row\n",
    "from fcts.utils import reparametrized_expanded_params, init_random_params, save_objects_to_yaml, load_objects_from_yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Load torch parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (for Mac) %env PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0\n",
    "device = 'mps' #put 'cuda' or 'cpu'\n",
    "device2 = 'mps' #put None or 'cuda'\n",
    "\n",
    "if not torch.backends.mps.is_available() and device != 'cpu':\n",
    "    print('Cuda is not available. Algorithm will use cpu')\n",
    "    device, device2 = torch.device('cpu'), None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Load parliament datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#votes: matrix gathering votes for several laws and politicians (1: positive, 0: missing/abstention, -1: negative)\n",
    "votes = np.loadtxt(\"data_parliament/votes.txt\",delimiter=\";\").astype(int)\n",
    "\n",
    "#deputes: Family name, Name, Political group \n",
    "deputes = json.load(open('data_parliament/deputes.json', 'r')) \n",
    "\n",
    "#texts:  political group demanding the law, title of demand, date, type (type of vote, type of majority, name of type of vote), \n",
    "texts = json.load(open('data_parliament/texts.json', 'r')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a - Parameter initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row length (number of deputes):  576\n",
      "col length (number of laws):  1256\n"
     ]
    }
   ],
   "source": [
    "n1, n2 = votes.shape\n",
    "print(\"row length (number of deputes): \",n1)\n",
    "print(\"col length (number of laws): \",n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a number of row and column clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select number of row clusters\n",
    "nq = 3# COMPLETE\n",
    "\n",
    "# Select number of column clusters\n",
    "nl = 5 # COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization of ($\\gamma, \\theta$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector_of_parameters = torch.tensor(init_random_params(n1, n2, nq, nl), requires_grad=True, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b- Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LBM_NMAR(\n",
    "    vector_of_parameters,\n",
    "    votes,\n",
    "    (n1, n2, nq, nl),\n",
    "    device=device,\n",
    "    device2=device2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c- Train model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform variational EM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "Start training LBM MNAR \n",
      " --------------------------------------------------------------------------------\n",
      "Number of row classes :  3\n",
      "Number of col classes :  5\n",
      " EM step  |   LBFGS iter  | criteria |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurafuentesvicente/M2 Maths&IA/Methodes Non Supervises avancees/Projet/LBM-MNAR/fcts/lbfgs.py:339: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
      "  p.data.add_(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0  |   1  | 336911.00000 |\n",
      " 0  |   2  | 322342.56250 |\n",
      " 0  |   3  | 316435.34375 |\n",
      " 0  |   4  | 314075.43750 |\n",
      " 0  |   5  | 313106.62500 |\n",
      " 0  |   6  | 312676.25000 |\n",
      " 0  |   7  | 312365.40625 |\n",
      " 0  |   8  | 312166.50000 |\n",
      " 0  |   9  | 312038.28125 |\n",
      " 0  |   10  | 311839.56250 |\n",
      " 0  |   11  | 311661.31250 |\n",
      " 0  |   12  | 311406.18750 |\n",
      " 0  |   13  | 311003.62500 |\n",
      " 0  |   14  | 310603.06250 |\n",
      " 0  |   15  | 310216.93750 |\n",
      " 0  |   16  | 309414.84375 |\n",
      " 0  |   17  | 309123.90625 |\n",
      " 0  |   18  | 309029.43750 |\n",
      " 0  |   19  | 308967.59375 |\n",
      " 0  |   20  | 308964.18750 |\n",
      " 0  |   21  | 308963.93750 |\n",
      "Curvature pair skipped due to failed criterion\n",
      " 0  |   22  | 308963.93750 |\n",
      "------------------------------  Optimizing next EM step  ------------------------------\n",
      " EM step  |   LBFGS iter  | criteria |\n",
      " 1  |   1  | 308165.31250 |\n",
      " 1  |   2  | 307158.06250 |\n",
      " 1  |   3  | 306827.53125 |\n",
      " 1  |   4  | 306514.75000 |\n",
      " 1  |   5  | 306299.12500 |\n",
      " 1  |   6  | 306041.96875 |\n",
      " 1  |   7  | 305945.46875 |\n",
      " 1  |   8  | 305882.93750 |\n",
      " 1  |   9  | 305852.12500 |\n",
      " 1  |   10  | 305835.59375 |\n",
      " 1  |   11  | 305824.53125 |\n",
      " 1  |   12  | 305814.59375 |\n",
      " 1  |   13  | 305803.09375 |\n",
      " 1  |   14  | 305796.68750 |\n",
      " 1  |   15  | 305791.06250 |\n",
      " 1  |   16  | 305786.81250 |\n",
      " 1  |   17  | 305785.75000 |\n",
      " 1  |   18  | 305785.28125 |\n",
      " 1  |   19  | 305784.78125 |\n",
      " 1  |   20  | 305784.56250 |\n",
      " 1  |   21  | 305784.46875 |\n",
      " 1  |   22  | 305784.46875 |\n",
      "------------------------------  Optimizing next EM step  ------------------------------\n",
      " EM step  |   LBFGS iter  | criteria |\n",
      " 2  |   1  | 305462.15625 |\n",
      " 2  |   2  | 305262.96875 |\n",
      " 2  |   3  | 305143.78125 |\n",
      " 2  |   4  | 305055.15625 |\n",
      " 2  |   5  | 304981.90625 |\n",
      " 2  |   6  | 304915.78125 |\n",
      " 2  |   7  | 304808.56250 |\n",
      " 2  |   8  | 304664.75000 |\n",
      " 2  |   9  | 304487.78125 |\n",
      " 2  |   10  | 304262.62500 |\n",
      " 2  |   11  | 304080.00000 |\n",
      " 2  |   12  | 303912.87500 |\n",
      " 2  |   13  | 303725.15625 |\n",
      " 2  |   14  | 303523.59375 |\n",
      " 2  |   15  | 303218.12500 |\n",
      " 2  |   16  | 302701.40625 |\n",
      " 2  |   17  | 301669.93750 |\n",
      " 2  |   18  | 300387.56250 |\n",
      " 2  |   19  | 298713.90625 |\n",
      " 2  |   20  | 297644.62500 |\n",
      " 2  |   21  | 297260.25000 |\n",
      " 2  |   22  | 297225.68750 |\n",
      " 2  |   23  | 297216.81250 |\n",
      " 2  |   24  | 297212.03125 |\n",
      " 2  |   25  | 297209.43750 |\n",
      " 2  |   26  | 297208.78125 |\n",
      " 2  |   27  | 297208.62500 |\n",
      " 2  |   28  | 297208.56250 |\n",
      " 2  |   29  | 297208.53125 |\n",
      "Objective function is NAN. Probably due to empty class\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    success, loglike = train_with_LBFGS(model)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt detected, stopping training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reparametrization of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(   nu_a,\n",
    "    rho_a,\n",
    "    nu_b,\n",
    "    rho_b,\n",
    "    nu_p,\n",
    "    rho_p,\n",
    "    nu_q,\n",
    "    rho_q,\n",
    "    tau_1,\n",
    "    tau_2,\n",
    "    mu_un,\n",
    "    sigma_sq_a,\n",
    "    sigma_sq_b,\n",
    "    sigma_sq_p,\n",
    "    sigma_sq_q,\n",
    "    alpha_1,\n",
    "    alpha_2,\n",
    "    pi,\n",
    ") = reparametrized_expanded_params(torch.cat((model.variationnal_params, model.model_params)), n1, n2, nq, nl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save parameters in YAML file (trained_parameters.yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict = {\n",
    "    'n1': n1, \n",
    "    'n2': n2,\n",
    "    'nq': nq, \n",
    "    'nl': nl,\n",
    "    'nu_a':nu_a,\n",
    "    'rho_a':rho_a,\n",
    "    'nu_b':nu_b,\n",
    "    'rho_b':rho_b,\n",
    "    'nu_p': nu_p,\n",
    "    'rho_p':rho_p,\n",
    "    'nu_q':nu_q,\n",
    "    'rho_q':rho_q,\n",
    "    'tau_1':tau_1,\n",
    "    'tau_2':tau_2,\n",
    "    'mu_un':mu_un,\n",
    "    'sigma_sq_a': sigma_sq_a,\n",
    "    'sigma_sq_b':sigma_sq_b,\n",
    "    'sigma_sq_p':sigma_sq_p,\n",
    "    'sigma_sq_q':sigma_sq_q,\n",
    "    'alpha_1':alpha_1,\n",
    "    'alpha_2':alpha_2,\n",
    "    'pi':pi,\n",
    "}\n",
    "\n",
    "save_objects_to_yaml(parameters_dict, 'trained_parameters.yaml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
