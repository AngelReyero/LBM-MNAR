{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from fcts.train_procedure import train_with_LBFGS\n",
    "from fcts.lbm_nmar import LBM_NMAR\n",
    "from fcts.lbfgs import FullBatchLBFGS\n",
    "from fcts.figures import groupes_politiques, pi_df, text_legend_row\n",
    "from fcts.utils import reparametrized_expanded_params, init_random_params, save_objects_to_yaml, load_objects_from_yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\" LOADING Arguments\" ################\n",
    "#%env PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0\n",
    "\n",
    "nq = 3 #enter nb of row classes\n",
    "nl = 5 #enter nb of col classes\n",
    "device = 'mps' #put 'cuda' or 'cpu'\n",
    "device2 = 'mps' #put None or 'cuda'\n",
    "\n",
    "if not torch.backends.mps.is_available() and device != 'cpu':\n",
    "    print('Cuda is not available. Algorithm will use cpu')\n",
    "    device, device2 = torch.device('cpu'), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\" LOADING DATASET\" ################\n",
    "\n",
    "votes = np.loadtxt(\"data_parliament/votes.txt\",delimiter=\";\").astype(int)\n",
    "deputes = json.load(open('data_parliament/deputes.json', 'r')) \n",
    "#deputes: Dataset with: Family name, Name, Political group \n",
    "texts = json.load(open('data_parliament/texts.json', 'r'))\n",
    "#texts: Dataset with: political group demanding, title of demand, date, type (type of vote, type of majority, name of type of vote), \n",
    "n1, n2 = votes.shape \n",
    "# shape of dataset: \n",
    "print(\"row length (nb of persons): \",n1)\n",
    "print(\"col length (nb of laws): \",n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\" Initialization \" ################\n",
    "vector_of_parameters = torch.tensor(init_random_params(n1, n2, nq, nl), requires_grad=True, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\" Model creation \"################\n",
    "model = LBM_NMAR(\n",
    "    vector_of_parameters,\n",
    "    votes,\n",
    "    (n1, n2, nq, nl),\n",
    "    device=device,\n",
    "    device2=device2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    success, loglike = train_with_LBFGS(model)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt detected, stopping training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of the model\n",
    "(   nu_a,\n",
    "    rho_a,\n",
    "    nu_b,\n",
    "    rho_b,\n",
    "    nu_p,\n",
    "    rho_p,\n",
    "    nu_q,\n",
    "    rho_q,\n",
    "    tau_1,\n",
    "    tau_2,\n",
    "    mu_un,\n",
    "    sigma_sq_a,\n",
    "    sigma_sq_b,\n",
    "    sigma_sq_p,\n",
    "    sigma_sq_q,\n",
    "    alpha_1,\n",
    "    alpha_2,\n",
    "    pi,\n",
    ") = reparametrized_expanded_params(torch.cat((model.variationnal_params, model.model_params)), n1, n2, nq, nl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict = {\n",
    "    'nu_a':nu_a,\n",
    "    'rho_a':rho_a,\n",
    "    'nu_b':nu_b,\n",
    "    'rho_b':rho_b,\n",
    "    'nu_p': nu_p,\n",
    "    'rho_p':rho_p,\n",
    "    'nu_q':nu_q,\n",
    "    'rho_q':rho_q,\n",
    "    'tau_1':tau_1,\n",
    "    'tau_2':tau_2,\n",
    "    'mu_un':mu_un,\n",
    "    'sigma_sq_a': sigma_sq_a,\n",
    "    'sigma_sq_b':sigma_sq_b,\n",
    "    'sigma_sq_p':sigma_sq_p,\n",
    "    'sigma_sq_q':sigma_sq_q,\n",
    "    'alpha_1':alpha_1,\n",
    "    'alpha_2':alpha_2,\n",
    "    'pi':pi,\n",
    "}\n",
    "\n",
    "save_objects_to_yaml(parameters_dict, 'trained_parameters.yaml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
